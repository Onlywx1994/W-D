
============1-th Epoch

============1-th Epoch

============1-th Epoch

============1-th Epoch

============1-th Epoch

============1-th Epoch

============1-th Epoch
{'train_logloss': 0.3717058577163546, 'train_auc': 0.8755159998332556, 'train_accuracy': 0.8314548078990203, 'test_logloss': 0.3578126597590605, 'test_auc': 0.8820981637013772, 'test_accuracy': 0.8357594742337694}

============2-th Epoch
{'train_logloss': 0.3585318401272659, 'train_auc': 0.8826610776315187, 'train_accuracy': 0.8343109855348423, 'test_logloss': 0.35432184434824504, 'test_auc': 0.8835211221074496, 'test_accuracy': 0.8363736871199557}

============3-th Epoch
{'train_logloss': 0.3560422037841707, 'train_auc': 0.8839007855975705, 'train_accuracy': 0.8353551795092289, 'test_logloss': 0.3527294981472875, 'test_auc': 0.8841609756066962, 'test_accuracy': 0.8372335851606166}

============4-th Epoch
{'train_logloss': 0.3549046895634502, 'train_auc': 0.8843922999964092, 'train_accuracy': 0.8352630447467829, 'test_logloss': 0.35197678833417445, 'test_auc': 0.8844887538967582, 'test_accuracy': 0.8367422148516676}

============5-th Epoch
{'train_logloss': 0.3541455809834132, 'train_auc': 0.8848322639399819, 'train_accuracy': 0.834495255059734, 'test_logloss': 0.351289150302848, 'test_auc': 0.8846989995401987, 'test_accuracy': 0.8373564277378539}

============6-th Epoch
{'train_logloss': 0.35347149990793447, 'train_auc': 0.8850709221175391, 'train_accuracy': 0.8357851417339762, 'test_logloss': 0.35106630057469373, 'test_auc': 0.8849400240585418, 'test_accuracy': 0.8372950064492353}

============7-th Epoch
{'train_logloss': 0.3530963416733249, 'train_auc': 0.8852880923401142, 'train_accuracy': 0.8356008722090845, 'test_logloss': 0.35077571351945985, 'test_auc': 0.8849628782095393, 'test_accuracy': 0.8376021128923284}

============8-th Epoch
{'train_logloss': 0.35283035283776515, 'train_auc': 0.8854387556652877, 'train_accuracy': 0.8349559288719633, 'test_logloss': 0.3505325525046286, 'test_auc': 0.8850483355884295, 'test_accuracy': 0.837847798046803}

============9-th Epoch
{'train_logloss': 0.3525085681566342, 'train_auc': 0.8855509934709636, 'train_accuracy': 0.8357237185590123, 'test_logloss': 0.3503862117836467, 'test_auc': 0.8852540856760929, 'test_accuracy': 0.8375406916037098}

============10-th Epoch
{'train_logloss': 0.352319637436058, 'train_auc': 0.8856528407024895, 'train_accuracy': 0.8354780258591566, 'test_logloss': 0.3502768458699024, 'test_auc': 0.8851821986027812, 'test_accuracy': 0.8372950064492353}

*************** TIME COST ****************
30.30 seconds for 10 epoches
16118.66 examples per second 

****************** LEARNING CURVE*********************
   train_logloss  train_auc  train_accuracy  test_logloss  test_auc  test_accuracy
0       0.371706   0.875516        0.831455      0.357813  0.882098       0.835759
1       0.358532   0.882661        0.834311      0.354322  0.883521       0.836374
2       0.356042   0.883901        0.835355      0.352729  0.884161       0.837234
3       0.354905   0.884392        0.835263      0.351977  0.884489       0.836742
4       0.354146   0.884832        0.834495      0.351289  0.884699       0.837356
5       0.353471   0.885071        0.835785      0.351066  0.884940       0.837295
6       0.353096   0.885288        0.835601      0.350776  0.884963       0.837602
7       0.352830   0.885439        0.834956      0.350533  0.885048       0.837848
8       0.352509   0.885551        0.835724      0.350386  0.885254       0.837541
9       0.352320   0.885653        0.835478      0.350277  0.885182       0.837295
