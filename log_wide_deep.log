1-th hidden layer,weight shape =(101, 64)
2-th hidden layer,weight shape =(64, 16)
final logit layer ,weight shape=(16, 1)
1-th hidden layer,weight shape =(101, 64)
2-th hidden layer,weight shape =(64, 16)
final logit layer ,weight shape=(16, 1)
1-th hidden layer,weight shape =(101, 64)
2-th hidden layer,weight shape =(64, 16)
final logit layer ,weight shape=(16, 1)

============1-th Epoch
{'train_logloss': 0.3716440139833204, 'train_auc': 0.8746886490767763, 'train_accuracy': 0.8283836491508246, 'test_logloss': 0.3566058740251195, 'test_auc': 0.8826666319567942, 'test_accuracy': 0.8362508445427185}

============2-th Epoch
{'train_logloss': 0.35652016809727877, 'train_auc': 0.8839018277504892, 'train_accuracy': 0.8347716593470716, 'test_logloss': 0.35131020172921895, 'test_auc': 0.8855701232472298, 'test_accuracy': 0.8379092193354216}

============3-th Epoch
{'train_logloss': 0.35267533702727855, 'train_auc': 0.8862839623190524, 'train_accuracy': 0.8366143545959891, 'test_logloss': 0.34870898946924656, 'test_auc': 0.8870903424798029, 'test_accuracy': 0.8393833302622689}

============4-th Epoch
{'train_logloss': 0.3503492657852149, 'train_auc': 0.8878180165745652, 'train_accuracy': 0.8372900095205921, 'test_logloss': 0.34695704529816573, 'test_auc': 0.8880800965854476, 'test_accuracy': 0.8396290154167434}

============5-th Epoch
{'train_logloss': 0.3484150395225228, 'train_auc': 0.8888488915413917, 'train_accuracy': 0.8370443168207364, 'test_logloss': 0.3458298736096637, 'test_auc': 0.8889993645584183, 'test_accuracy': 0.840366070880167}

============6-th Epoch
{'train_logloss': 0.3472267624921619, 'train_auc': 0.8898196776218606, 'train_accuracy': 0.8388255888946899, 'test_logloss': 0.3445846437584647, 'test_auc': 0.8896949106753976, 'test_accuracy': 0.8411031263435906}

============7-th Epoch
{'train_logloss': 0.3459990696716526, 'train_auc': 0.8905906386189266, 'train_accuracy': 0.8386720309572802, 'test_logloss': 0.34359956765430755, 'test_auc': 0.8903517531935696, 'test_accuracy': 0.8414716540753026}

============8-th Epoch
{'train_logloss': 0.34504955701536544, 'train_auc': 0.8912389815545124, 'train_accuracy': 0.8401461871564141, 'test_logloss': 0.3427987732717054, 'test_auc': 0.890858381420098, 'test_accuracy': 0.8420858669614889}

============9-th Epoch
{'train_logloss': 0.34410840570836104, 'train_auc': 0.8917850284105331, 'train_accuracy': 0.8400540523939682, 'test_logloss': 0.3423902488458178, 'test_auc': 0.8914133211890599, 'test_accuracy': 0.8427000798476753}

============10-th Epoch
{'train_logloss': 0.3435192806187824, 'train_auc': 0.8922597135874866, 'train_accuracy': 0.8407297073185713, 'test_logloss': 0.34155866891563685, 'test_auc': 0.8917108747076059, 'test_accuracy': 0.8427000798476753}

*************** TIME COST ****************
53.72 seconds for 10 epoches
9092.70 examples per second 

****************** LEARNING CURVE*********************
   train_logloss  train_auc  train_accuracy  test_logloss  test_auc  test_accuracy
0       0.371644   0.874689        0.828384      0.356606  0.882667       0.836251
1       0.356520   0.883902        0.834772      0.351310  0.885570       0.837909
2       0.352675   0.886284        0.836614      0.348709  0.887090       0.839383
3       0.350349   0.887818        0.837290      0.346957  0.888080       0.839629
4       0.348415   0.888849        0.837044      0.345830  0.888999       0.840366
5       0.347227   0.889820        0.838826      0.344585  0.889695       0.841103
6       0.345999   0.890591        0.838672      0.343600  0.890352       0.841472
7       0.345050   0.891239        0.840146      0.342799  0.890858       0.842086
8       0.344108   0.891785        0.840054      0.342390  0.891413       0.842700
9       0.343519   0.892260        0.840730      0.341559  0.891711       0.842700
1-th hidden layer,weight shape =(101, 64)
2-th hidden layer,weight shape =(64, 16)
final logit layer ,weight shape=(16, 1)

============1-th Epoch
{'train_logloss': 0.37372126031900904, 'train_auc': 0.8715499321259218, 'train_accuracy': 0.8271858972390282, 'test_logloss': 0.3500097099254516, 'test_auc': 0.887639898036613, 'test_accuracy': 0.8359437380996253}

============2-th Epoch
{'train_logloss': 0.34831554528756553, 'train_auc': 0.8902404184873388, 'train_accuracy': 0.8386413193697982, 'test_logloss': 0.3401140470943231, 'test_auc': 0.8937665773619284, 'test_accuracy': 0.8427000798476753}

============3-th Epoch
{'train_logloss': 0.34024366847390625, 'train_auc': 0.895137696260095, 'train_accuracy': 0.843094499554682, 'test_logloss': 0.334488591392116, 'test_auc': 0.8973208055785038, 'test_accuracy': 0.8446041397948529}

============4-th Epoch
{'train_logloss': 0.33505251469295466, 'train_auc': 0.8983886561757982, 'train_accuracy': 0.8472712754522281, 'test_logloss': 0.33069516932299237, 'test_auc': 0.8994418087941853, 'test_accuracy': 0.8471838339168356}

============5-th Epoch
{'train_logloss': 0.3316093848277029, 'train_auc': 0.9003048348878953, 'train_accuracy': 0.8479162187893492, 'test_logloss': 0.32834068357711704, 'test_auc': 0.9004990589651732, 'test_accuracy': 0.8501934770591487}

============6-th Epoch
{'train_logloss': 0.32959778170287457, 'train_auc': 0.9013260260872544, 'train_accuracy': 0.8481926230766869, 'test_logloss': 0.3271928440186076, 'test_auc': 0.9010389020305485, 'test_accuracy': 0.8500092131932928}

============7-th Epoch
{'train_logloss': 0.32842272860740634, 'train_auc': 0.9018633436227877, 'train_accuracy': 0.8474555449771198, 'test_logloss': 0.32631803545542204, 'test_auc': 0.9013929218206123, 'test_accuracy': 0.8507462686567164}

============8-th Epoch
{'train_logloss': 0.32757467862363937, 'train_auc': 0.9023762273156328, 'train_accuracy': 0.8475783913270477, 'test_logloss': 0.32564178879711936, 'test_auc': 0.9016388287216249, 'test_accuracy': 0.8502548983477674}

============9-th Epoch
{'train_logloss': 0.3268535020477952, 'train_auc': 0.9027043507098402, 'train_accuracy': 0.8482540462516508, 'test_logloss': 0.325406733214292, 'test_auc': 0.9017588496060952, 'test_accuracy': 0.8499477919046742}

============10-th Epoch
{'train_logloss': 0.3264550191911118, 'train_auc': 0.9029264582608469, 'train_accuracy': 0.8482540462516508, 'test_logloss': 0.32507573941036655, 'test_auc': 0.9018780863819997, 'test_accuracy': 0.8506848473680978}

*************** TIME COST ****************
51.51 seconds for 10 epoches
9481.42 examples per second 

****************** LEARNING CURVE*********************
   train_logloss  train_auc  train_accuracy  test_logloss  test_auc  test_accuracy
0       0.373721   0.871550        0.827186      0.350010  0.887640       0.835944
1       0.348316   0.890240        0.838641      0.340114  0.893767       0.842700
2       0.340244   0.895138        0.843094      0.334489  0.897321       0.844604
3       0.335053   0.898389        0.847271      0.330695  0.899442       0.847184
4       0.331609   0.900305        0.847916      0.328341  0.900499       0.850193
5       0.329598   0.901326        0.848193      0.327193  0.901039       0.850009
6       0.328423   0.901863        0.847456      0.326318  0.901393       0.850746
7       0.327575   0.902376        0.847578      0.325642  0.901639       0.850255
8       0.326854   0.902704        0.848254      0.325407  0.901759       0.849948
9       0.326455   0.902926        0.848254      0.325076  0.901878       0.850685
